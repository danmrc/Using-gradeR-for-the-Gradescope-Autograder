# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r")
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r", bugsAreFatal = F)
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r", bugsAreFatal = F, suppress_warnings = T)
calcGrades <- function(submission_dir, your_test_file, suppress_warnings = TRUE, verbose = FALSE, bugsAreFatal = TRUE){
if(missing(submission_dir) | missing(your_test_file))
stop("the first two arguments are required")
paths <- list.files(path = submission_dir,
recursive = T,
pattern = "\\.r$",
ignore.case = T)
number_questions <- length(testthat::test_file(your_test_file,
reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
number_students <- length(paths)
score_data <- data.frame("id" = vector(mode = "character", length = number_students),
matrix(data = 0, nrow = number_students,
ncol = number_questions),
stringsAsFactors = F)
student_num <- 1
for(path in paths ){
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
# source each assignment
# we have to decide whether we are lenient on warnings and/or errors
if(suppress_warnings && bugsAreFatal){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else if( suppress_warnings && !bugsAreFatal ){
cat("WOOOOOOOOOOOOT!")
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
# thanks to Josh O'Brien's answer at
# https://stackoverflow.com/questions/14612190/is-there-a-way-to-source-and-continue-after-an-error
ll <- parse(file = tmp_full_path)
for (i in seq_along(ll)) {
tryCatch(eval(ll[[i]], testEnv),
error = function(e) message("Non-fatal error encountered. Skipping over this line...  ", as.character(e)))
}
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else { #not suppressing warnings and bugs are fatal
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
source(tmp_full_path, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
}
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(your_test_file,
reporter = lr,
env = testEnv)
# parse the output
score_data[student_num,1] <- tmp_full_path
for(q in (1:number_questions)){
# true or false if question was correct
success <- methods::is(lr$results$as_list()[[q]]$results[[1]],"expectation_success")
# TODO incorporate point values
if(success){
score_data[student_num, q+1] <- 1
}else{
score_data[student_num, q+1] <- 0
}
}
# clear out all of the student's data from global environment
rm(list = setdiff(ls(testEnv),
c("path", "paths", "submission_dir",
"student_num", "number_questions",
"number_students", "score_data",
"your_test_file", "path")), envir = testEnv)
# increment
student_num <- student_num + 1
}
# make the column names prettier before returning everything
colnames(score_data)[-1] <-  paste("q", as.character(1:number_questions), sep = "")
return(score_data)
}
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r", bugsAreFatal = F, suppress_warnings = T)
derp <- parse("../example_submissions/taylor_assignment.r")
?parse
parse("1::3")
parse(text = "1::3")
calcGrades <- function(submission_dir, your_test_file, suppress_warnings = TRUE, verbose = FALSE, bugsAreFatal = TRUE){
if(missing(submission_dir) | missing(your_test_file))
stop("the first two arguments are required")
paths <- list.files(path = submission_dir,
recursive = T,
pattern = "\\.r$",
ignore.case = T)
number_questions <- length(testthat::test_file(your_test_file,
reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
number_students <- length(paths)
score_data <- data.frame("id" = vector(mode = "character", length = number_students),
matrix(data = 0, nrow = number_students,
ncol = number_questions),
stringsAsFactors = F)
student_num <- 1
for(path in paths ){
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
# source each assignment
# we have to decide whether we are lenient on warnings and/or errors
if(suppress_warnings && bugsAreFatal){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else if( suppress_warnings && !bugsAreFatal ){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
# thanks to Josh O'Brien's answer at
# https://stackoverflow.com/questions/14612190/is-there-a-way-to-source-and-continue-after-an-error
sf <- srcfile(filename = tmp_full_path)
try(parse(file = tmp_full_path, srcfile = sf))
ll <- getParseData(sf)
for (i in seq_along(ll)) {
tryCatch(eval(ll[[i]], testEnv),
error = function(e) message("Non-fatal error encountered. Skipping over this line...  ", as.character(e)))
}
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else { #not suppressing warnings and bugs are fatal
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
source(tmp_full_path, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
}
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(your_test_file,
reporter = lr,
env = testEnv)
# parse the output
score_data[student_num,1] <- tmp_full_path
for(q in (1:number_questions)){
# true or false if question was correct
success <- methods::is(lr$results$as_list()[[q]]$results[[1]],"expectation_success")
# TODO incorporate point values
if(success){
score_data[student_num, q+1] <- 1
}else{
score_data[student_num, q+1] <- 0
}
}
# clear out all of the student's data from global environment
rm(list = setdiff(ls(testEnv),
c("path", "paths", "submission_dir",
"student_num", "number_questions",
"number_students", "score_data",
"your_test_file", "path")), envir = testEnv)
# increment
student_num <- student_num + 1
}
# make the column names prettier before returning everything
colnames(score_data)[-1] <-  paste("q", as.character(1:number_questions), sep = "")
return(score_data)
}
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r", bugsAreFatal = F, suppress_warnings = T)
tmp_full_path
# thanks to Josh O'Brien's answer at
# https://stackoverflow.com/questions/14612190/is-there-a-way-to-source-and-continue-after-an-error
sf <- srcfile(filename = tmp_full_path)
sf
?srcfile
try(parse(file = tmp_full_path, srcfile = sf))
getParseData(sf)
library(evaluate)
evaluate(file(tmp_full_path))
?evaluate(file(tmp_full_path))
evaluate(file(tmp_full_path), envir = testEnv)
calcGrades <- function(submission_dir, your_test_file, suppress_warnings = TRUE, verbose = FALSE, bugsAreFatal = TRUE){
if(missing(submission_dir) | missing(your_test_file))
stop("the first two arguments are required")
paths <- list.files(path = submission_dir,
recursive = T,
pattern = "\\.r$",
ignore.case = T)
number_questions <- length(testthat::test_file(your_test_file,
reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
number_students <- length(paths)
score_data <- data.frame("id" = vector(mode = "character", length = number_students),
matrix(data = 0, nrow = number_students,
ncol = number_questions),
stringsAsFactors = F)
student_num <- 1
for(path in paths ){
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
# source each assignment
# we have to decide whether we are lenient on warnings and/or errors
if(suppress_warnings && bugsAreFatal){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else if( suppress_warnings && !bugsAreFatal ){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
# thanks to Josh O'Brien's answer at
# https://stackoverflow.com/questions/14612190/is-there-a-way-to-source-and-continue-after-an-error
evaluate(file(tmp_full_path), envir = testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else { #not suppressing warnings and bugs are fatal
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
source(tmp_full_path, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
}
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(your_test_file,
reporter = lr,
env = testEnv)
# parse the output
score_data[student_num,1] <- tmp_full_path
for(q in (1:number_questions)){
# true or false if question was correct
success <- methods::is(lr$results$as_list()[[q]]$results[[1]],"expectation_success")
# TODO incorporate point values
if(success){
score_data[student_num, q+1] <- 1
}else{
score_data[student_num, q+1] <- 0
}
}
# clear out all of the student's data from global environment
rm(list = setdiff(ls(testEnv),
c("path", "paths", "submission_dir",
"student_num", "number_questions",
"number_students", "score_data",
"your_test_file", "path")), envir = testEnv)
# increment
student_num <- student_num + 1
}
# make the column names prettier before returning everything
colnames(score_data)[-1] <-  paste("q", as.character(1:number_questions), sep = "")
return(score_data)
}
calcGrades <- function(submission_dir, your_test_file, suppress_warnings = TRUE, verbose = FALSE, bugsAreFatal = TRUE){
if(missing(submission_dir) | missing(your_test_file))
stop("the first two arguments are required")
paths <- list.files(path = submission_dir,
recursive = T,
pattern = "\\.r$",
ignore.case = T)
number_questions <- length(testthat::test_file(your_test_file,
reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
number_students <- length(paths)
score_data <- data.frame("id" = vector(mode = "character", length = number_students),
matrix(data = 0, nrow = number_students,
ncol = number_questions),
stringsAsFactors = F)
student_num <- 1
for(path in paths ){
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
# source each assignment
# we have to decide whether we are lenient on warnings and/or errors
if(suppress_warnings && bugsAreFatal){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
suppressWarnings(source(tmp_full_path, testEnv))
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else if( suppress_warnings && !bugsAreFatal ){
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
# thanks to Josh O'Brien's answer at
# https://stackoverflow.com/questions/14612190/is-there-a-way-to-source-and-continue-after-an-error
evaluate(file(tmp_full_path), envir = testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
})
} else { #not suppressing warnings and bugs are fatal
tryCatch({
if(verbose)
cat("grading: ", path, "\n")
source(tmp_full_path, testEnv)
}, error = function(e) {
cat("Unable to run: ",  path, "\n")
cat("Error message: \n")
message(e)
cat("\n")
}, warning = function(w){
cat("Produced a warning: ", path, "\n")
message(w)
cat("\n")
})
}
# test the student's submissions
lr <- testthat::ListReporter$new()
out <- testthat::test_file(your_test_file,
reporter = lr,
env = testEnv)
# parse the output
score_data[student_num,1] <- tmp_full_path
for(q in (1:number_questions)){
# true or false if question was correct
success <- methods::is(lr$results$as_list()[[q]]$results[[1]],"expectation_success")
# TODO incorporate point values
if(success){
score_data[student_num, q+1] <- 1
}else{
score_data[student_num, q+1] <- 0
}
}
# clear out all of the student's data from global environment
rm(list = setdiff(ls(testEnv),
c("path", "paths", "submission_dir",
"student_num", "number_questions",
"number_students", "score_data",
"your_test_file", "path")), envir = testEnv)
# increment
student_num <- student_num + 1
}
# make the column names prettier before returning everything
colnames(score_data)[-1] <-  paste("q", as.character(1:number_questions), sep = "")
return(score_data)
}
# set working directory to place where you have
# a. your grading file with the tests
# b. all external .csv files that students use for their assignment
setwd("~/gradescopeR/autograding_code_and_data/")
# this is the directory with all of the student submissions
submissionDir <- "../example_submissions/"
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r", bugsAreFatal = F, suppress_warnings = T)
file("../example_submissions/taylor_assignment.r")
evaluate(file("../example_submissions/taylor_assignment.r"))
evaluate(file("../example_submissions/taylor_assignment.r"))
?replay
evaluate(input = file("../example_submissions/taylor_assignment.r"))
replay(evaluate(input = file("../example_submissions/taylor_assignment.r")))
?replay(evaluate(input = file("../example_submissions/taylor_assignment.r")))
res <- evaluate(input = file("../example_submissions/taylor_assignment.r"))
res
rnorm("a")
?evaluate
?source
?parse
?srcfile()
?system.file()
srcfile("../example_submissions/taylor_assignment.r")
?srcfile("../example_submissions/taylor_assignment.r")
txt <- "
x <- 1
an error
"
sf <- srcfile("txt")
sf
try(parse(text = txt, srcfile = sf))
getParseData(sf)
?eval
ll
?eval
?parse
readLines(tmp_full_path)
# set working directory to place where you have
# a. your grading file with the tests
# b. all external .csv files that students use for their assignment
setwd("~/gradescopeR/autograding_code_and_data/")
# this is the directory with all of the student submissions
submissionDir <- "../example_submissions/"
submission_dir = submissionDir
your_test_file = "assignment1_grading_file.r"
if(missing(submission_dir) | missing(your_test_file))
stop("the first two arguments are required")
paths <- list.files(path = submission_dir,
recursive = T,
pattern = "\\.r$",
ignore.case = T)
number_questions <- length(testthat::test_file(your_test_file,
reporter = "minimal"))
if(number_questions == 0)
stop("you need at least one graded question")
number_students <- length(paths)
score_data <- data.frame("id" = vector(mode = "character", length = number_students),
matrix(data = 0, nrow = number_students,
ncol = number_questions),
stringsAsFactors = F)
student_num <- 1
paths
path <- paths[3]
# run student's submission in a separate environment
tmp_full_path <- paste(submission_dir, path, sep = "")
testEnv <- new.env()
readLines(tmp_full_path)
submissionText <- readLines(tmp_full_path)
sf <- srcfile("submissionText")
sf
try(parse(text=submissionText, srcfile = sf))
try(parse(text=submissionText, srcfile = sf), silent = T)
getParseData(sf)
?srcfile
?eval
eval(sf)
df
d
eval(getParseData(sf))
?getParseData
getParseText(sf)
sf
# load in the package
library(gradeR)
# set working directory to place where you have
# a. your grading file with the tests
# b. all external .csv files that students use for their assignment
setwd("~/gradescopeR/autograding_code_and_data/")
# this is the directory with all of the student submissions
submissionDir <- "../example_submissions/"
# get the grades
calcGrades(submission_dir = submissionDir,
your_test_file = "assignment1_grading_file.r")
?test_that
